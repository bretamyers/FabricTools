{"cells":[{"cell_type":"markdown","source":["### Parameters to update\n","##### Make sure notebook is attached to a lakehouse to log results\n","##### Two tables will be created. QueryResults and RunResults"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d94e7d5b-db72-4777-b700-297f8baaaf13"},{"cell_type":"code","source":["FabricDWWorkspaceName = 'WS_DW_Query_Cost_Test_Take_Nine'\n","FabricDWName = 'WH_SampleData'\n","ConcurrencyNum = 1 # This should be equal or greater than the length of the dataframe with the queryies defined below\n","CapacityMetricsWorkspace = 'Microsoft Fabric Capacity Metrics'\n","CapacityMetricsDataset = 'Fabric Capacity Metrics'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.1931484Z","session_start_time":"2024-09-24T21:44:15.1802516Z","execution_start_time":"2024-09-24T21:44:25.3198089Z","execution_finish_time":"2024-09-24T21:44:27.4195009Z","parent_msg_id":"aba05996-ffda-4a51-9b84-06d9b8344ea9"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"20be0399-9430-4b52-a3ab-1c911fc0d69a"},{"cell_type":"code","source":["print(f\"{FabricDWWorkspaceName=}\")\n","print(f\"{FabricDWName=}\")\n","print(f\"{ConcurrencyNum=}\")\n","print(f\"{CapacityMetricsWorkspace=}\")\n","print(f\"{CapacityMetricsDataset=}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.1961408Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:27.8178501Z","execution_finish_time":"2024-09-24T21:44:28.0508804Z","parent_msg_id":"17929cc3-74fd-4a03-8989-4788eb858d36"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["FabricDWWorkspaceName='WS_DW_Query_Cost_Test_Take_Nine'\nFabricDWName='WH_SampleData'\nConcurrencyNum=1\nCapacityMetricsWorkspace='Microsoft Fabric Capacity Metrics'\nCapacityMetricsDataset='Fabric Capacity Metrics'\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f493545a-4048-4721-a9ef-eeed8e883a28"},{"cell_type":"code","source":["queryList = [\n","    # Transaction\n","    'SELECT COUNT(*) FROM FactTransaction'\n","    ,'''SELECT\tCOUNT(*)\n","FROM\tFactTransaction AS ft\n","JOIN\tDimDate AS d\n","ON\t\td.Date = ft.DateKey\n","JOIN\tDimPaymentMethod AS pm\n","ON\t\tpm.PaymentMethodKey= ft.PaymentMethodKey\n","JOIN\tDimTransactionType AS tt\n","ON\t\ttt.TransactionTypeKey = ft.TransactionTypeKey\n","JOIN\tDimSupplier AS s\n","ON\t\ts.SupplierKey = ft.SupplierKey\n","JOIN\tDimCustomer AS cu\n","ON\t\tcu.CustomerKey = ft.CustomerKey\n","JOIN\tDimCustomer AS cuBill\n","ON\t\tcuBill.CustomerKey = ft.BillToCustomerKey'''\n","    # Order\n","    ,'SELECT COUNT(*) FROM FactOrder'\n","    ,'''SELECT\tCOUNT(*)\n","FROM\tFactOrder AS fo\n","JOIN\tDimDate AS dOrder\n","ON\t\tdOrder.Date = fo.OrderDateKey\n","LEFT JOIN\tDimDate AS dPicked\n","ON\t\tdPicked.Date = fo.PickedDateKey\n","JOIN\tDimStockItem AS si\n","ON\t\tsi.StockItemKey = fo.StockItemKey\n","JOIN\tDimCity AS c\n","ON\t\tc.CityKey = fo.CityKey\n","JOIN\tDimEmployee AS e\n","ON\t\te.EmployeeKey = fo.SalespersonKey\n","JOIN\tDimEmployee AS ePicker\n","ON\t\tePicker.EmployeeKey = fo.PickerKey\n","JOIN\tDimCustomer AS cu\n","ON\t\tcu.CustomerKey = fo.CustomerKey'''\n","    # FactMovement\n","    ,'SELECT COUNT(*) FROM FactMovement'\n","    ,'''SELECT\tCOUNT(*)\n","FROM\tFactMovement AS fm\n","JOIN\tDimDate AS d\n","ON\t\td.Date = fm.DateKey\n","JOIN\tDimStockItem AS si\n","ON\t\tsi.StockItemKey = fm.StockItemKey\n","JOIN\tDimTransactionType AS tt\n","ON\t\ttt.TransactionTypeKey = fm.TransactionTypeKey\n","JOIN\tDimSupplier AS s\n","ON\t\ts.SupplierKey = fm.SupplierKey\n","JOIN\tDimCustomer AS c\n","ON\t\tc.CustomerKey = fm.CustomerKey'''\n","    # FactPurchase\n","    ,'SELECT COUNT(*) FROM FactPurchase'\n","    ,'''SELECT\tCOUNT(*)\n","FROM\tFactPurchase AS fp\n","JOIN\tDimDate AS d\n","ON\t\td.Date = fp.DateKey\n","JOIN\tDimStockItem AS si\n","ON\t\tsi.StockItemKey = fp.StockItemKey\n","JOIN\tDimSupplier AS s\n","ON\t\ts.SupplierKey = fp.SupplierKey'''\n","    # StockHolding\n","    ,'SELECT COUNT(*) FROM FactStockHolding'\n","    ,'''SELECT\tCOUNT(*)\n","FROM\tFactStockHolding AS fsh\n","JOIN\tDimStockItem AS si\n","ON\t\tsi.StockItemKey = fsh.StockItemKey'''\n","    # Stored Procedures\n","    ,'''EXEC sp_Ingest'''\n","    ,'''EXEC sp_Query'''\n","    # Query with multiple statements\n","    ,'''IF OBJECT_ID('dbo.DimDate', 'U') IS NOT NULL DROP TABLE dbo.DimDate; CREATE TABLE dbo.DimDate AS SELECT * FROM LH_SampleData.dbo.DimDate'''\n","]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2119515Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:28.4296315Z","execution_finish_time":"2024-09-24T21:44:28.6504235Z","parent_msg_id":"2acb3350-94da-457a-8c1a-77be3a8b5ba3"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dd4b5a5a-dfa7-43b0-b8a7-b4b3849a7559"},{"cell_type":"code","source":["executorCoreCnt = int(spark.conf.get('spark.executor.cores'))\n","executorInstances = int(spark.conf.get('spark.executor.instances'))\n","maxConcurrency = ConcurrencyNum if ConcurrencyNum < (executorCoreCnt * executorInstances) else (executorCoreCnt * executorInstances)\n","\n","rddQueries = sc.parallelize(queryList, maxConcurrency)\n","rddQueriesWithId = rddQueries.zipWithUniqueId().map(lambda x: [x[1], (x[1], x[0])] )#, tokenstruct, runId]) # zipWithUniqueId is faster than ZipWithIndex but could create gaps in the Ids generated\n","rddQueriesWithId = rddQueriesWithId.partitionBy(maxConcurrency, lambda k: k ) # is this even needed?\n","print(rddQueriesWithId.glom().map(len).collect())  # Get length of each partition to check for even distribution of rows in the partitions. This will tell us if the number of queries are evenly distributed\n","\n","# TODO adjust verbage of this\n","# print(f'Max currency of spark session is {(executorCoreCnt * executorInstances)}\\nDefined concurrency is {concurrencyNum}\\nCan only run {maxConcurrency} queries concurrently for this spark session')\n","displayHTML(f\"\"\"\n","<p><span style=\"font-size:20px;\"><strong>Max currency of spark session is </strong><i><strong>{maxConcurrency}</strong></i></span></p>\n","<p><span style=\"font-size:20px;\"><strong>Defined concurrency is </strong><i><strong>{ConcurrencyNum}</strong></i></span></p>\n","<p><span style=\"font-size:20px;\"><strong>Can only run </strong><i><strong>{maxConcurrency}</strong></i><strong> queries concurrently for this spark session</strong></span></p>\n","\"\"\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2145285Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:29.043217Z","execution_finish_time":"2024-09-24T21:44:30.5718666Z","parent_msg_id":"27d8f150-2490-4608-829e-9133fa5eb0c0"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[12]\n"]},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<p><span style=\"font-size:20px;\"><strong>Max currency of spark session is </strong><i><strong>1</strong></i></span></p>\n<p><span style=\"font-size:20px;\"><strong>Defined concurrency is </strong><i><strong>1</strong></i></span></p>\n<p><span style=\"font-size:20px;\"><strong>Can only run </strong><i><strong>1</strong></i><strong> queries concurrently for this spark session</strong></span></p>\n"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"de6ed022-d969-45cd-8fd2-93b34357f16f"},{"cell_type":"code","source":["import requests\n","\n","header = {'Authorization': f'Bearer {mssparkutils.credentials.getToken(\"pbi\")}'\n","          ,\"Content-Type\": \"application/json\"\n","          }\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces', headers=header)\n","\n","while True:\n","    workspaceFound = False\n","    for workspace in response.json().get('value'):\n","        if workspace.get('displayName') == FabricDWWorkspaceName:\n","            fabricDWWorkspaceId = workspace.get('id')\n","            workspaceFound = True\n","            break\n","    \n","    if workspaceFound:\n","        break\n","    elif workspaceFound == False and response.json().get('continuationToken'):\n","        responseStatus = requests.request(method='get', url=response.json().get('continuationUri'), headers=header)\n","    else:\n","        print(f\"Workspace was not found and no contination token found - {response.json()}\")\n","        break\n","\n","print(f'{fabricDWWorkspaceId = }\\n{FabricDWWorkspaceName = }')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2173872Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:30.9528192Z","execution_finish_time":"2024-09-24T21:44:32.1228291Z","parent_msg_id":"7f97057a-9dd5-4568-ad3f-edfa7025abc8"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["fabricDWWorkspaceId = '41a063a3-ef2a-4938-8570-3f5b2331f584'\nFabricDWWorkspaceName = 'WS_DW_Query_Cost_Test_Take_Nine'\n"]}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2f726386-0439-4ceb-9f96-b6f562e01135"},{"cell_type":"code","source":["import requests\n","\n","header = {'Authorization': f'Bearer {mssparkutils.credentials.getToken(\"pbi\")}'\n","          ,\"Content-Type\": \"application/json\"\n","          }\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces/{fabricDWWorkspaceId}', headers=header)\n","workspaceName = response.json().get('displayName')\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces/{fabricDWWorkspaceId}', headers=header)\n","capacityId = response.json().get('capacityId')\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/capacities', headers=header)\n","for capacity in response.json().get('value'):\n","    if capacity.get('id') == capacityId:\n","        capacityRegion = capacity.get('region')\n","        capacityName = capacity.get('displayName')\n","        capacitySku = capacity.get('sku')\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces/{fabricDWWorkspaceId}/warehouses', headers=header)\n","warehouse = [warehouse for warehouse in response.json().get('value') if warehouse.get('displayName') == FabricDWName][0]\n","fabricDWServer = warehouse.get('properties').get('connectionString')\n","warehouseId = warehouse.get('id')\n","\n","print(f'{warehouseId = }\\n{fabricDWServer = }\\n{workspaceName = }\\n{capacityId = }\\n{capacityRegion = }\\n{capacityName = }\\n{capacitySku = }')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2198394Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:32.4976158Z","execution_finish_time":"2024-09-24T21:44:37.226268Z","parent_msg_id":"51aa275c-780b-406b-9e0b-963e48d84e08"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["warehouseId = '179a51e7-8282-4172-9e2e-63aa5e0f8a5f'\nfabricDWServer = 'n52dzjnhphme5jslxpytuo62ni-unr2aqjk544etblqh5nsgmpvqq.datawarehouse.fabric.microsoft.com'\nworkspaceName = 'WS_DW_Query_Cost_Test_Take_Nine'\ncapacityId = 'e36151a3-66ab-4bc5-b4f9-8a6e39f79d95'\ncapacityRegion = 'East US 2'\ncapacityName = 'fabricdemobam'\ncapacitySku = 'F32'\n"]}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f1fd34b-c182-47ff-8d87-d8fdd550ad3e"},{"cell_type":"code","source":["response = requests.request(method='get', url=\"https://prices.azure.com/api/retail/prices?$filter=skuName eq 'Fabric Capacity'\", headers=header)\n","for capacity in response.json().get('Items'):\n","    if capacity.get('armRegionName') == capacityRegion.replace(' ', '').lower():\n","        costReserved = capacity.get('retailPrice') / 12 / 730 / 60 / 60 # get the amount per CU second\n","        costPayGo = costReserved / (156.334/262.80) # constant saving of ~41%. 156.334 is the resevered price of a region. 262.80 is the paygo price of a region\n","print(f'{costReserved = :.10f}\\n{costPayGo = :.10f}') # per CU"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2218658Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:37.597525Z","execution_finish_time":"2024-09-24T21:44:38.3817527Z","parent_msg_id":"238119ba-4c95-4fad-bd15-a05ffb0e3012"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["costReserved = 0.0000297438\ncostPayGo = 0.0000499998\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6509449a-48a5-4da1-a7c7-43a75ecd7325"},{"cell_type":"markdown","source":["##### Define the queries to be executed. These are single line queries so use /* */ for commenting out code vs --"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e5bcecd-ac6c-45bf-9ebb-66fe8949ab54"},{"cell_type":"code","source":["from notebookutils import mssparkutils  \n","from pyspark.sql import functions as F\n","from pyspark.sql import Row\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, TimestampType, DoubleType\n","import pyodbc, struct, itertools, time, datetime, re, uuid, json\n","\n","connectionString = f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={fabricDWServer};Database={FabricDWName}'\n","\n","# Use the credentials of the user executing the notebook\n","token = bytes(mssparkutils.credentials.getToken('pbi'), \"UTF-8\")\n","encoded_bytes = bytes(itertools.chain.from_iterable(zip(token, itertools.repeat(0))))\n","tokenstruct = struct.pack(\"<i\", len(encoded_bytes)) + encoded_bytes\n","\n","runId = str(uuid.uuid4())\n","runStartDateTimeUTC = datetime.datetime.now(datetime.timezone.utc)\n","runStartTimeEpoch = int(runStartDateTimeUTC.timestamp()*1000)\n","\n","print(f'{runId = }\\n{runStartDateTimeUTC = }\\n{runStartTimeEpoch = }')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2229973Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:38.738249Z","execution_finish_time":"2024-09-24T21:44:39.5240977Z","parent_msg_id":"379faa94-0d21-4559-b46c-cd4e72dc57f8"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["runId = '0d2d13ee-9aa1-4eaf-988f-528e12d628fa'\nrunStartDateTimeUTC = datetime.datetime(2024, 9, 24, 21, 44, 38, 830403, tzinfo=datetime.timezone.utc)\nrunStartTimeEpoch = 1727214278830\n"]}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"44a4596a-e954-4ccc-aa49-0d32c1500013"},{"cell_type":"code","source":["from delta.tables import *\n","\n","with pyodbc.connect(connectionString, attrs_before = { 1256:tokenstruct }) as conn:\n","    with conn.cursor() as cursor:\n","        cursor.execute('''SELECT @@VERSION AS DWVersion\n","                            ,@@SERVERNAME AS ServerGuid\n","                            ,DB_NAME() AS DWName\n","        ''')\n","        resultList = cursor.fetchall()\n","        resultColumns = columns = [column[0] for column in cursor.description]\n","        cursor.commit()\n","        resultSet = [dict(zip(resultColumns, [str(col) for col in row])) for row in resultList]\n","\n","        cursor.execute(f'''SELECT [is_vorder_enabled] AS IsVOrderEnabled, [data_lake_log_publishing_desc] AS DataLakeLogPublishingDesc\n","                            ,[data_lake_log_publishing] AS DataLakeLogPublishing, [create_date] AS DWCreateDate, [compatibility_level] AS CompatibilityLevel\n","                            FROM sys.databases \n","                            WHERE [name] = '{FabricDWName}'\n","            ''')\n","\n","        resultList = cursor.fetchall()\n","        resultColumns = columns = [column[0] for column in cursor.description]\n","        cursor.commit()\n","        resultSet.extend([dict(zip(resultColumns, [str(col) for col in row])) for row in resultList])\n","\n","        df = spark.createDataFrame([dict(zip(resultColumns, [str(col) for col in row])) for row in resultList])\n","\n","dfRun = (df.withColumn('RunStartDateTimeUTC', F.lit(runStartDateTimeUTC).cast(TimestampType()))\n","            .withColumn('RunStartTimeEpoch', F.lit(runStartTimeEpoch).cast(LongType()))\n","            .withColumn('RunId', F.lit(runId).cast(StringType()))\n","            .withColumn('DWConnectionString', F.lit(fabricDWServer).cast(StringType()))\n","            .withColumn('QueriesExecutedCnt', F.lit(len(queryList)).cast(IntegerType()))\n","            .withColumn('RunConcurrency', F.lit(maxConcurrency).cast(IntegerType()))\n","\n","            .withColumn('DWGuid', F.lit(warehouseId).cast(StringType())) # TODO\n","            .withColumn('WorkspaceName', F.lit(workspaceName).cast(StringType())) # TODO\n","            .withColumn('WorkspaceGuid', F.lit(fabricDWWorkspaceId).cast(StringType())) # TODO\n","            .withColumn('CapacityName', F.lit(capacityName).cast(StringType())) # TODO\n","            .withColumn('CapacityGuid', F.lit(capacityId).cast(StringType())) # TODO\n","            .withColumn('CapacitySKU', F.lit(capacitySku).cast(StringType())) # TODO\n","            .withColumn('CapacityRegion', F.lit(capacityRegion).cast(StringType())) # TODO\n","\n","            .withColumn('RunEndDatetimeUTC', F.lit(None).cast(TimestampType()))\n","            .withColumn('RunEndTimeEpochMS', F.lit(None).cast(LongType()))\n","            .withColumn('RunDurationMS', F.lit(None).cast(LongType()))\n","            .withColumn('RunCUSeconds', F.lit(None).cast(DoubleType()))\n","            .withColumn('RunCostPayGo', F.lit(None).cast(DoubleType()))\n","            .withColumn('RunCostReserved', F.lit(None).cast(DoubleType()))\n","            \n","            .withColumn('CapacityDailyCUSeconds', F.lit(60*60*24*int(capacitySku.split('F')[1])))\n","            .withColumn('CapacityDailyCostPayGo', F.lit(costPayGo * 60*60*24*int(capacitySku.split('F')[1])))\n","            .withColumn('CapacityDailyCostReserved', F.lit(costReserved * 60*60*24*int(capacitySku.split('F')[1])))\n","        )\n","\n","\n","# # TODO add a merge so that if you need to rerun from this step, it doesn't insert a new record\n","dfRun.select(\"RunId\"\n","        ,\"DWConnectionString\"\n","        ,\"QueriesExecutedCnt\"\n","        ,\"RunConcurrency\"\n","        ,\"DWGuid\"\n","        ,\"WorkspaceName\"\n","        ,\"WorkspaceGuid\"\n","        ,\"CapacityName\"\n","        ,\"CapacityGuid\"\n","        ,\"CapacitySKU\"\n","        ,\"CapacityRegion\"\n","        ,\"CompatibilityLevel\"\n","        ,\"DWCreateDate\"\n","        ,\"DataLakeLogPublishing\"\n","        ,\"DataLakeLogPublishingDesc\"\n","        ,\"IsVOrderEnabled\"\n","        ,\"RunStartDateTimeUTC\"\n","        ,\"RunStartTimeEpoch\"\n","        ,\"RunEndDatetimeUTC\"\n","        ,\"RunEndTimeEpochMS\"\n","        ,\"RunDurationMS\"\n","        ,\"RunCUSeconds\"\n","        ,\"RunCostPayGo\"\n","        ,\"RunCostReserved\"\n","        ,\"CapacityDailyCUSeconds\"\n","        ,\"CapacityDailyCostPayGo\"\n","        ,\"CapacityDailyCostReserved\"\n","    )\n","\n","if spark.catalog.tableExists(\"RunResults\"):\n","\n","    dtRunResults = DeltaTable.forName(spark, \"RunResults\")\n","\n","    (dtRunResults.alias('t')\n","        .merge(dfRun.alias('s')\n","            ,f't.runId = s.RunId'\n","            )\n","        .whenNotMatchedInsertAll()\n","    ).execute() \n","else:\n","    dfRun.write.format('delta').mode('append').saveAsTable('RunResults')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2251062Z","session_start_time":null,"execution_start_time":"2024-09-24T21:44:39.8827667Z","execution_finish_time":"2024-09-24T21:45:00.7199141Z","parent_msg_id":"53041a4f-e39d-4219-8289-abbd7a20e714"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f1633b8f-665d-4393-a63c-174effbb1ba9"},{"cell_type":"code","source":["from pyspark import SparkContext, SparkConf\n","import pyodbc \n","\n","def get_result_set(cursor):\n","    if cursor.description:\n","        resultList = cursor.fetchall()\n","        resultColumns = columns = [column[0] for column in cursor.description]\n","    else:\n","        resultList = []\n","        resultColumns = []\n","    return [dict(zip(resultColumns, [str(col) for col in row])) for row in resultList]\n","\n","def execute_query(iterator):\n","    queryMetrics = []\n","    for queryInfo in iterator:\n","        queryId = queryInfo[1][0]\n","        queryStatement = queryInfo[1][1]\n","        with pyodbc.connect(connectionString, attrs_before = { 1256:tokenstruct }) as conn:\n","            with conn.cursor() as cursor:\n","                queryStartDateTimeUTC = datetime.datetime.now(datetime.timezone.utc)\n","                startTime = int(round(time.time() * 1000))\n","\n","                cursor.execute(queryStatement)\n","                endTime = int(round(time.time() * 1000))\n","                queryEndDateTimeUTC = datetime.datetime.now(datetime.timezone.utc)\n","                \n","                queryMessage = str(cursor.messages) if cursor.messages else \"\"\n","                resultSet = get_result_set(cursor)\n","\n","                while cursor.nextset():\n","                    queryMessage += \",\".join([str(cursor.messages) if cursor.messages else \"\"])\n","                    resultSet.append(get_result_set(cursor))\n","                \n","                statementId = ','.join(re.findall(r\"Statement ID: \\{([A-F0-9\\-]+)\\}\", queryMessage)) if re.findall(r\"Statement ID: \\{([A-F0-9\\-]+)\\}\", queryMessage) else \"\"\n","                queryHash = ','.join(re.findall(r\"Query hash: (0x[A-F0-9]+)\", queryMessage)) if re.findall(r\"Query hash: (0x[A-F0-9]+)\", queryMessage) else \"\"\n","                distributionRequestId = ','.join(re.findall(r\"Distributed request ID: \\{([A-F0-9\\-]+)\\}\", queryMessage)) if re.findall(r\"Distributed request ID: \\{([A-F0-9\\-]+)\\}\", queryMessage) else \"\"\n","                resultSetJsonString = json.dumps(resultSet)\n","\n","                cursor.commit()\n","\n","                queryId = str(uuid.uuid4())\n","                queryMetrics.append([runId, queryId, queryStatement, queryStartDateTimeUTC, queryEndDateTimeUTC\n","                        ,queryMessage, startTime, endTime, endTime - startTime\n","                        ,statementId, queryHash, distributionRequestId, resultSetJsonString\n","                        ])\n","    return queryMetrics\n","\n","queriesExecuted = rddQueriesWithId.mapPartitions(execute_query)\n","\n","dfQueriesExecuted = queriesExecuted.toDF(schema=StructType([\n","    StructField(\"RunId\", StringType(), False),\n","    StructField(\"QueryId\", StringType(), False),\n","    StructField(\"QueryStatement\", StringType(), False),\n","    StructField(\"QueryStartDateTimeUTC\", TimestampType(), False),\n","    StructField(\"QueryEndDateTimeUTC\", TimestampType(), False),\n","    StructField(\"ReturnMessage\", StringType(), False),\n","    StructField(\"QueryStartTimeEpochMS\", LongType(), False),\n","    StructField(\"QueryEndTimeEpochMS\", LongType(), False),\n","    StructField(\"QueryDurationMS\", LongType(), False),\n","    StructField(\"StatementId\", StringType(), False),\n","    StructField(\"QueryHash\", StringType(), False),\n","    StructField(\"DistributionRequestId\", StringType(), False),\n","    StructField(\"ResultSet\", StringType(), False)\n","    ]))\n","\n","dfFinal = dfQueriesExecuted.withColumn('QueryCUSeconds', F.lit(None).cast(DoubleType())).withColumn('QueryCostPayGo', F.lit(None).cast(DoubleType())).withColumn('QueryCostReserved', F.lit(None).cast(DoubleType()))\n","dfFinal.write.format('delta').mode('append').saveAsTable('QueryResults')\n","\n","runEndDateTimeUTC = datetime.datetime.now(datetime.timezone.utc)\n","runEndTimeEpoch = int(runEndDateTimeUTC.timestamp()*1000)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.225924Z","session_start_time":null,"execution_start_time":"2024-09-24T21:45:01.1392524Z","execution_finish_time":"2024-09-24T21:45:37.4772998Z","parent_msg_id":"e7a3a4d4-8bdd-4750-b22c-9d45f2b558bc"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"a7a25284-d19a-4120-b2bf-9326efd16033"},{"cell_type":"code","source":["statementList = spark.sql(f'SELECT ARRAY_JOIN(COLLECT_SET(CONCAT(\"\\\\\"\", StatementId, \"\\\\\"\")), \", \") AS Statements FROM (SELECT EXPLODE(SPLIT(StatementId, \",\")) AS StatementId FROM QueryResults WHERE runId = \"{runId}\") AS a ').collect()[0].asDict().get('Statements')\n","# We have to explode by statement ids since a sql query may have multiple queries within it\n","queriesExecutedCnt = spark.sql(f'SELECT COUNT(StatementId) AS QueryCnt FROM (SELECT EXPLODE(SPLIT(StatementId, \",\")) AS StatementId FROM QueryResults WHERE runId = \"{runId}\") AS a ').collect()[0].asDict().get('QueryCnt') \n","print(f'{runId = }\\n{statementList = }\\n{queriesExecutedCnt = }')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2278497Z","session_start_time":null,"execution_start_time":"2024-09-24T21:45:37.8278691Z","execution_finish_time":"2024-09-24T21:45:42.6965166Z","parent_msg_id":"b61582d0-a516-4237-9cb6-a00e00336ffa"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["runId = '0d2d13ee-9aa1-4eaf-988f-528e12d628fa'\nstatementList = '\"33A655DC-EA1A-4130-A272-78FC2A918E53\", \"49D14862-51AB-4173-BE2A-A7821D4E07BF\", \"CE110DE9-E753-43C0-80C8-73D7E5B150ED\", \"4F26DC75-A7D7-435D-B70D-7F03AD0214D6\", \"69516C44-4A17-439F-B4EC-3F6619155748\", \"29634577-8C4B-4208-A223-DE494F7A5CD1\", \"7ECD8E14-793D-436A-814E-5521D4F9436A\", \"A73C7CFF-171D-4581-A02A-06C5430B192F\", \"38E656B1-65BD-4DAD-8421-A23938EC9204\", \"0A456AE7-BBB6-4199-BEEE-4AA50DB4C2B3\", \"54DB14CB-19F4-48AC-B3C4-86E580E4A238\", \"5DA623E1-EDDB-4CDA-8460-8AF7557BCE68\", \"7A5E64B9-4907-4236-8502-AC9E6B47D0A2\", \"6A4938BD-F2EF-4D0E-8A9C-115FD623CE00\", \"A63595D5-0C2F-44C4-A411-F363258D5AD6\"'\nqueriesExecutedCnt = 15\n"]}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"fdf916df-8027-4011-a8ec-dd3fedc1c2b2"},{"cell_type":"code","source":["from delta.tables import *\n","\n","dtRunResults = DeltaTable.forName(spark, \"RunResults\")\n","\n","df_final = spark.createDataFrame(data=[(runEndDateTimeUTC, runEndTimeEpoch, )], schema=['RunEndDateTimeUTC', 'RunEndTimeEpochMS'])\n","\n","(dtRunResults.alias('t')\n","    .merge(df_final.alias('s')\n","        ,f't.RunId = \"{runId}\"'\n","        )\n","    .whenMatchedUpdate(set=\n","        {'RunEndDatetimeUTC': 's.RunEndDateTimeUTC'\n","        ,'RunEndTimeEpochMS': 's.RunEndTimeEpochMS'\n","        ,'RunDurationMS': 's.RunEndTimeEpochMS - t.RunStartTimeEpoch'\n","        }\n","        )\n",").execute() "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2316649Z","session_start_time":null,"execution_start_time":"2024-09-24T21:45:43.0963987Z","execution_finish_time":"2024-09-24T21:45:51.1347097Z","parent_msg_id":"94ab7a18-d309-41b1-bee9-be027fcb2604"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"9d44baaf-dc59-433f-8b7e-c5a2a124f3fe"},{"cell_type":"code","source":["import sempy.fabric as fabric\n","from datetime import timedelta\n","from pyspark.sql.functions import col, lit, sum, min, max\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType\n","\n","def get_capacity_metrics_usage(time_point, operation_id_list):\n","\t\n","\tschema = StructType([\n","\t\tStructField(\"Items[ItemId]\", \tStringType(), \t\tTrue),\n","\t\tStructField(\"Items[ItemKind]\", \tStringType(), \t\tTrue),\n","\t\tStructField(\"Items[ItemName]\", \tStringType(), \t\tTrue),\n","\t\tStructField(\"TimePointBackgroundDetail[OperationStartTime]\", \tTimestampType(), \tTrue),\n","\t\tStructField(\"TimePointBackgroundDetail[OperationEndTime]\", \t\tTimestampType(), \tTrue),\n","\t\tStructField(\"TimePointBackgroundDetail[OperationId]\", \t\t\tStringType(), \t\tTrue),\n","\t\tStructField(\"Sum_CUs\", \t\tDoubleType(), \t\tTrue),\n","\t\tStructField(\"Sum_Duration\", IntegerType(), \t\tTrue)\n","\t])\n","\n","\tdax_command = f\"\"\"\n","\tDEFINE\n","\t\tMPARAMETER 'CapacityID' \t= \"{capacityId}\"\n","\t\tMPARAMETER 'TimePoint' \t\t= (DATE({time_point.year}, {time_point.month}, {time_point.day}) + TIME({time_point.hour}, {time_point.minute}, {time_point.second}))\n","\n","\t\tVAR __Var_CapacityId\t= {{\"{capacityId}\"}}\n","\t\tVAR __Var_OperationId\t= {{{statementList}}}\n","\n","\t\tVAR __Filter_OperationId \t= TREATAS(__Var_OperationId, 'TimePointBackgroundDetail'[OperationId])\n","\t\tVAR __Filter_CapacityId \t= TREATAS(__Var_CapacityId, 'Capacities'[capacityId])\n","\n","\t\tVAR OperationCUs = \n","\t\t\tSUMMARIZECOLUMNS(\n","\t\t\t\t'Items'[ItemId],\n","\t\t\t\t'Items'[ItemKind],\n","\t\t\t\t'Items'[ItemName],\n","\t\t\t\t'TimePointBackgroundDetail'[OperationStartTime],\n","\t\t\t\t'TimePointBackgroundDetail'[OperationEndTime],\n","\t\t\t\t'TimePointBackgroundDetail'[OperationId],\n","\t\t\t\t__Filter_OperationId,\n","\t\t\t\t__Filter_CapacityId,\n","\t\t\t\t\"Sum_CUs\", CALCULATE(SUM('TimePointBackgroundDetail'[Total CU (s)])),\n","\t\t\t\t\"Sum_Duration\", CALCULATE(SUM('TimePointBackgroundDetail'[Duration (s)]))\n","\t\t\t)\n","\n","\tEVALUATE\n","\t\tOperationCUs\n","\t\"\"\"\n","\n","\tdf_dax = fabric.evaluate_dax(dax_string = dax_command, dataset = CapacityMetricsDataset, workspace = CapacityMetricsWorkspace)\n","\n","\tdf = (spark.createDataFrame(data=df_dax, schema=schema).withColumn(\"TimePoint\", lit(time_point)).select(\n","\t\t\tcol(\"TimePoint\")\n","\t\t\t,col(\"Items[ItemId]\").alias(\"ItemId\")\n","\t\t\t,col(\"Items[ItemKind]\").alias(\"ItemKind\")\n","\t\t\t,col(\"Items[ItemName]\").alias(\"ItemName\")\n","\t\t\t,col(\"TimePointBackgroundDetail[OperationStartTime]\").alias(\"StartTime\")\n","\t\t\t,col(\"TimePointBackgroundDetail[OperationEndTime]\").alias(\"EndTime\")\n","\t\t\t,col(\"TimePointBackgroundDetail[OperationId]\").alias(\"OperationId\")\n","\t\t\t,col(\"Sum_CUs\").cast(DoubleType()).alias(\"Sum_CUs\")\n","\t\t\t,col(\"Sum_Duration\").cast(IntegerType()).alias(\"Sum_Duration\"))\n","\t\t)\n","\n","\treturn df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2495983Z","session_start_time":null,"execution_start_time":"2024-09-24T21:45:51.5153918Z","execution_finish_time":"2024-09-24T21:46:01.4212814Z","parent_msg_id":"294b6efe-3add-46a0-b44a-c7091ca746f1"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b09fd036-6768-4fe9-b1f9-fea79ed5e7b0"},{"cell_type":"code","source":["'''\n","Get the capacity usage for the queries that were executed.\n","This ensures that the background operations are captured no matter what time they are run as they are smoothed over a 24 hour time period.\n","Next, filter that down to the distinct records. This is necessary because a record may show up in the today and tomorrow datasets depending on the time it was run.\n","Nest, aggregate the records into a single record. This is necessary becuase some operations will have two entries, one under the executing user and one under the user \"System\".\n","'''\n","\n","# # Continues to query the metrica app to get the data. Data can delayed by a few minutes.\n","# # We retry every minute until 15 minutes has passed.\n","for retryCnt in range(15):\n","    df_today    = get_capacity_metrics_usage(runStartDateTimeUTC, statementList)\n","    df_tomorrow = get_capacity_metrics_usage(runStartDateTimeUTC + timedelta(hours = 24), statementList)\n","    df_all_days = df_today.unionAll(df_tomorrow)\n","    df_distinct = df_all_days.select('ItemId', 'ItemKind', 'ItemName', 'StartTime', 'EndTime', 'OperationId', 'Sum_CUs', 'Sum_Duration').distinct()\n","    df_final    = df_distinct.groupBy('ItemId', 'ItemKind', 'ItemName', 'OperationId').agg(min(\"StartTime\").alias(\"StartTime\"), max(\"EndTime\").alias(\"EndTime\"), sum(\"Sum_CUs\").alias(\"QueryCUSeconds\"), sum(\"Sum_Duration\").alias(\"SumDuration\"))\n","\n","    print(f'{df_final.count()} queries of the {queriesExecutedCnt} that have been found in the capacity metrics model. ', end='')\n","    if df_final.count() == queriesExecutedCnt:\n","        break\n","    else:\n","        print('Sleeping for a minute...')\n","        time.sleep(60)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.250702Z","session_start_time":null,"execution_start_time":"2024-09-24T21:46:01.8116292Z","execution_finish_time":"2024-09-24T21:51:22.3422747Z","parent_msg_id":"333d4f24-90b3-4f5b-884c-7dd70c91d1b2"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 16, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0 queries of the 15 that have been found in the capacity metrics model. Sleeping for a minute...\n0 queries of the 15 that have been found in the capacity metrics model. Sleeping for a minute...\n0 queries of the 15 that have been found in the capacity metrics model. Sleeping for a minute...\n0 queries of the 15 that have been found in the capacity metrics model. Sleeping for a minute...\n15 queries of the 15 that have been found in the capacity metrics model. "]}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"9d68bfa2-1f97-47af-a21c-230459507da7"},{"cell_type":"code","source":["from pyspark.sql.functions import sum\n","\n","dfQueryResults = spark.table(\"QueryResults\")\n","\n","dfQueryResultsCleansed = (dfQueryResults.join(df_final, dfQueryResults.StatementId.contains(df_final.OperationId)) \n","    .filter(dfQueryResults.RunId == runId) \n","    .groupBy(dfQueryResults.RunId, dfQueryResults.StatementId) \n","    .agg(sum(df_final.QueryCUSeconds).alias(\"QueryCUSeconds\"), sum(df_final.SumDuration).alias(\"SumDuration\")\n","    ))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2537126Z","session_start_time":null,"execution_start_time":"2024-09-24T21:51:22.7277923Z","execution_finish_time":"2024-09-24T21:51:26.2142343Z","parent_msg_id":"520add78-326f-4fbd-a0c2-94d6059a649a"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f9ffd41b-12e4-4c5a-aeae-0dccf30add3e"},{"cell_type":"markdown","source":["##### Update the QueryResults table with the CUSeconds and QueryCost derived from the Capacity Metrics App"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"13aa53bc-c865-491d-881a-3206e8cfbfad"},{"cell_type":"code","source":["from delta.tables import *\n","\n","dtQueryResults = DeltaTable.forName(spark, \"QueryResults\")\n","\n","(dtQueryResults.alias('t')\n","    .merge(dfQueryResultsCleansed.alias('s')\n","        ,f't.runId = s.RunId AND t.StatementId = s.StatementId'\n","        )\n","    .whenMatchedUpdate(set=\n","        {'QueryCUSeconds': 's.QueryCUSeconds'\n","        ,'QueryCostPayGo': f's.QueryCUSeconds * {costPayGo}'\n","        ,'QueryCostReserved': f's.QueryCUSeconds * {costReserved}'\n","        }\n","        )\n",").execute() "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.254652Z","session_start_time":null,"execution_start_time":"2024-09-24T21:51:26.5841181Z","execution_finish_time":"2024-09-24T21:51:43.055442Z","parent_msg_id":"5e20b036-75a9-4388-84fb-4dddd2b5090b"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 18, Finished, Available, Finished)"},"metadata":{}}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b93c6bdf-7984-489a-b3bf-c3de6080aa60"},{"cell_type":"markdown","source":["##### Update the RunResults table with cost of run"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8343c8b6-52c9-414d-8bf7-962982409336"},{"cell_type":"code","source":["from delta.tables import *\n","\n","dtRunResults = DeltaTable.forName(spark, \"RunResults\")\n","dtRunResultsCleansed = spark.sql(f'SELECT SUM(COALESCE(QueryCUSeconds, 0)) AS RunCUSeconds, SUM(COALESCE(QueryCostPayGo, 0)) AS RunCostPayGo, SUM(COALESCE(QueryCostReserved, 0)) AS RunCostReserved FROM QueryResults WHERE RunId = \"{runId}\"')\n","\n","(dtRunResults.alias('t')\n","    .merge(dtRunResultsCleansed.alias('s')\n","        ,f't.RunId = \"{runId}\"'\n","        )\n","    .whenMatchedUpdate(set=\n","        {'RunCUSeconds': 's.RunCUSeconds'\n","        ,'RunCostPayGo': f's.RunCUSeconds * {costPayGo}'  # This could be different looking at the tables separately due to rounding\n","        ,'RunCostReserved': f's.RunCUSeconds * {costReserved}'  # This could be different looking at the tables separately due to rounding\n","        }\n","        )\n",").execute()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2555743Z","session_start_time":null,"execution_start_time":"2024-09-24T21:51:43.4198626Z","execution_finish_time":"2024-09-24T21:51:51.586384Z","parent_msg_id":"f3f46002-1951-41dd-8037-42a47e160e19"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 19, Finished, Available, Finished)"},"metadata":{}}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":true},"id":"12730f91-3044-4f4c-908c-87d657f3ace5"},{"cell_type":"code","source":["displayHTML(f\"\"\"<script src=\"https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js\"></script>\n","<p style=\"margin-bottom:0\"><span style=\"font-size:20px;\"><strong>/*<br>Reference T-SQL - </strong></span><span style=\"font-size:20px;\"><strong>See running sql statements on the DW. Used to verify query(s) are executing and that the concurrency is working correctly.<br>*/</strong></span></p>\n","<pre class=\"prettyprint\"><p style=\"margin-top:0;\">SELECT\td.name AS 'database_name'\n","\t,s.login_name\n","\t,r.[session_id]\n","\t,r.start_time\n","\t,r.STATUS\n","\t,r.total_elapsed_time\n","\t,r.command\n","\t,CASE /* Uses statement start and end offset to figure out what statement is running */\n","\t\tWHEN r.[statement_start_offset] > 0\n","\t\t\tTHEN\n","\t\t\t\t/* The start of the active command is not at the beginning of the full command text */\n","\t\t\t\tCASE r.[statement_end_offset]\n","\t\t\t\t\tWHEN - 1\n","\t\t\t\t\t\tTHEN\n","\t\t\t\t\t\t\t/* The end of the full command is also the end of the active statement */\n","\t\t\t\t\t\t\tSUBSTRING(t.TEXT, (r.[statement_start_offset] / 2) + 1, 2147483647)\n","\t\t\t\t\tELSE\n","\t\t\t\t\t\t/* The end of the active statement is not at the end of the full command */\n","\t\t\t\t\t\tSUBSTRING(t.TEXT, (r.[statement_start_offset] / 2) + 1, (r.[statement_end_offset] - r.[statement_start_offset]) / 2)\n","\t\t\t\t\tEND\n","\t\tELSE\n","\t\t\t/* 1st part of full command is running */\n","\t\t\tCASE r.[statement_end_offset]\n","\t\t\t\tWHEN - 1\n","\t\t\t\t\tTHEN\n","\t\t\t\t\t\t/* The end of the full command is also the end of the active statement */\n","\t\t\t\t\t\tRTRIM(LTRIM(t.[text]))\n","\t\t\t\tELSE\n","\t\t\t\t\t/* The end of the active statement is not at the end of the full command */\n","\t\t\t\t\tLEFT(t.TEXT, (r.[statement_end_offset] / 2) + 1)\n","\t\t\t\tEND\n","\t\tEND AS [executing_statement]\n","\t,t.[text] AS [parent_batch]\n","\t,s.[program_name]\n","\t,r.query_hash\n","\t,r.query_plan_hash\n","\t,r.dist_statement_id\n","\t,r.[label]\n","\t,s.client_interface_name\n","\t,r.[sql_handle]\n","\t,c.client_net_address\n","\t,c.connection_id\n","FROM\tsys.dm_exec_requests r\n","CROSS APPLY sys.[dm_exec_sql_text](r.[sql_handle]) t\n","JOIN\tsys.dm_exec_sessions s ON r.session_id = s.session_id\n","JOIN\tsys.dm_exec_connections c ON s.session_id = c.session_id\n","JOIN\tsys.databases d ON d.database_id = r.database_id\n","WHERE\tr.dist_statement_id != '00000000-0000-0000-0000-000000000000'\n","AND\tr.session_id <> @@SPID\n","AND\ts.program_name NOT IN ('QueryInsights','DMS')\n","</pre></p>\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"535874ce-8165-4ce3-bb88-950999d34045","normalized_state":"finished","queued_time":"2024-09-24T21:44:14.2589416Z","session_start_time":null,"execution_start_time":"2024-09-24T21:51:51.9603674Z","execution_finish_time":"2024-09-24T21:51:52.1878418Z","parent_msg_id":"29a9a90b-b574-43f9-83d2-03c101e2760f"},"text/plain":"StatementMeta(, 535874ce-8165-4ce3-bb88-950999d34045, 20, Finished, Available, Finished)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script src=\"https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js\"></script>\n<p style=\"margin-bottom:0\"><span style=\"font-size:20px;\"><strong>/*<br>Reference T-SQL - </strong></span><span style=\"font-size:20px;\"><strong>See running sql statements on the DW. Used to verify query(s) are executing and that the concurrency is working correctly.<br>*/</strong></span></p>\n<pre class=\"prettyprint\"><p style=\"margin-top:0;\">SELECT\td.name AS 'database_name'\n\t,s.login_name\n\t,r.[session_id]\n\t,r.start_time\n\t,r.STATUS\n\t,r.total_elapsed_time\n\t,r.command\n\t,CASE /* Uses statement start and end offset to figure out what statement is running */\n\t\tWHEN r.[statement_start_offset] > 0\n\t\t\tTHEN\n\t\t\t\t/* The start of the active command is not at the beginning of the full command text */\n\t\t\t\tCASE r.[statement_end_offset]\n\t\t\t\t\tWHEN - 1\n\t\t\t\t\t\tTHEN\n\t\t\t\t\t\t\t/* The end of the full command is also the end of the active statement */\n\t\t\t\t\t\t\tSUBSTRING(t.TEXT, (r.[statement_start_offset] / 2) + 1, 2147483647)\n\t\t\t\t\tELSE\n\t\t\t\t\t\t/* The end of the active statement is not at the end of the full command */\n\t\t\t\t\t\tSUBSTRING(t.TEXT, (r.[statement_start_offset] / 2) + 1, (r.[statement_end_offset] - r.[statement_start_offset]) / 2)\n\t\t\t\t\tEND\n\t\tELSE\n\t\t\t/* 1st part of full command is running */\n\t\t\tCASE r.[statement_end_offset]\n\t\t\t\tWHEN - 1\n\t\t\t\t\tTHEN\n\t\t\t\t\t\t/* The end of the full command is also the end of the active statement */\n\t\t\t\t\t\tRTRIM(LTRIM(t.[text]))\n\t\t\t\tELSE\n\t\t\t\t\t/* The end of the active statement is not at the end of the full command */\n\t\t\t\t\tLEFT(t.TEXT, (r.[statement_end_offset] / 2) + 1)\n\t\t\t\tEND\n\t\tEND AS [executing_statement]\n\t,t.[text] AS [parent_batch]\n\t,s.[program_name]\n\t,r.query_hash\n\t,r.query_plan_hash\n\t,r.dist_statement_id\n\t,r.[label]\n\t,s.client_interface_name\n\t,r.[sql_handle]\n\t,c.client_net_address\n\t,c.connection_id\nFROM\tsys.dm_exec_requests r\nCROSS APPLY sys.[dm_exec_sql_text](r.[sql_handle]) t\nJOIN\tsys.dm_exec_sessions s ON r.session_id = s.session_id\nJOIN\tsys.dm_exec_connections c ON s.session_id = c.session_id\nJOIN\tsys.databases d ON d.database_id = r.database_id\nWHERE\tr.dist_statement_id != '00000000-0000-0000-0000-000000000000'\nAND\tr.session_id <> @@SPID\nAND\ts.program_name NOT IN ('QueryInsights','DMS')\n</pre></p>\n"},"metadata":{}}],"execution_count":18,"metadata":{"jupyter":{"source_hidden":true,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"editable":true,"run_control":{"frozen":false},"collapsed":false},"id":"487dfa72-4492-47c5-b5c3-b1fbc595f985"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3ea5b5fe-d61b-4356-a234-44112e32e5cc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"53f4dd68-8fae-4b90-aaa3-342133af7c56","default_lakehouse_name":"LH_QueryResults","default_lakehouse_workspace_id":"41a063a3-ef2a-4938-8570-3f5b2331f584"}}},"nbformat":4,"nbformat_minor":5}