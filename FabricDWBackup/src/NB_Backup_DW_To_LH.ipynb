{"cells":[{"cell_type":"markdown","source":["##### Parameters\n","- workspaceName - The name of the workspace where the source warehouse exists\n","- warehouseName - The name of the warehouse that is to be backed up\n","- workspaceBackupName - The name of the workspace that the lakehouse for backups exists\n","- lakehouseBackupName - The name of the lakehouse used for back ups"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"33a5c338-f911-4a80-8561-522cc4d81c82"},{"cell_type":"code","source":["workspaceName = 'WS_Demo_InternetSales'\n","warehouseName = 'WH_InternetSales'\n","\n","workspaceBackupName = 'WS_Demo_InternetSales_Backup'\n","lakehouseBackupsName = 'LH_DW_Backups'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"97583691-a2b7-4e6a-8fcb-2223b1f1e888"},{"cell_type":"markdown","source":["##### Copy the data from the Warehouse delta folders a separate Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fa226348-68ad-41f9-bd59-37b09898dd90"},{"cell_type":"code","source":["import datetime\n","\n","# https://www.rakirahman.me/directory-recursion-synapse/\n","\n","def deep_ls(path: str, max_depth=1):\n","    \"\"\"\n","    List all files and folders in specified path and\n","    subfolders within maximum recursion depth.\n","    \"\"\"\n","\n","    # List all files in path\n","    li = mssparkutils.fs.ls(path)\n","\n","    # Return all files\n","    for x in li:\n","        if x.size != 0:\n","            yield x\n","\n","    # If the max_depth has not been reached, start\n","    # listing files and folders in subdirectories\n","    if max_depth > 1:\n","        for x in li:\n","            if x.size != 0:\n","                continue\n","            for y in deep_ls(x.path, max_depth - 1):\n","                yield y\n","\n","    # If max_depth has been reached,\n","    # return the folders\n","    else:\n","        for x in li:\n","            if x.size == 0:\n","                yield x\n","\n","\n","fileList = deep_ls(f'abfss://{workspaceName}@onelake.dfs.fabric.microsoft.com/{warehouseName}.datawarehouse/Tables', max_depth=2)\n","\n","nowDatetime = datetime.datetime.now(datetime.timezone.utc)\n","backupDatetime = nowDatetime.strftime(\"%Y%m%d_%H%M\")\n","print(f'{workspaceName = }')\n","print(f'{backupDatetime = }')\n","\n","for file in fileList:\n","    schema = file.path.split('/')[-2]\n","    table = file.name\n","    print(f'{schema = }, {table = }')\n","    df = spark.read.format('delta').load(file.path)\n","    df.write.mode('overwrite').format('delta').save(f'abfss://{workspaceBackupName}@onelake.dfs.fabric.microsoft.com/{lakehouseBackupsName}.Lakehouse/Files/{workspaceName}/{warehouseName}/{backupDatetime}/{schema}/{table}')\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8ba470f-b040-4823-ae64-c4110069baee"},{"cell_type":"markdown","source":["##### Drop old backups - default backupRetentionCnt is set to 2 meaning it will keep the last 2 backups."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d2e5e39-7d1e-4f58-8d97-1bb6b4397129"},{"cell_type":"code","source":["backupList = mssparkutils.fs.ls(f'abfss://{workspaceBackupName}@onelake.dfs.fabric.microsoft.com/{lakehouseBackupsName}.Lakehouse/Files/{workspaceName}/{warehouseName}')\n","backupRetentionCnt = 2\n","\n","for i, file in enumerate(backupList):\n","    if len(backupList) - i > backupRetentionCnt:\n","        print(f'Removing directory \"{file.path}\"')\n","        mssparkutils.fs.rm(file.path, recurse=True)\n","    else:\n","        break"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e1e0028a-fe93-4dba-aa85-437525c21a18"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"209e468b-1a4f-4e64-aa33-947d0d95180e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"5f07e922-7e5c-41d0-8174-c7694efae0b1","default_lakehouse_name":"LH_DW_Backups","default_lakehouse_workspace_id":"59664bd4-4ae0-4217-a188-bcb3d6abf770","known_lakehouses":[{"id":"5f07e922-7e5c-41d0-8174-c7694efae0b1"}]}}},"nbformat":4,"nbformat_minor":5}