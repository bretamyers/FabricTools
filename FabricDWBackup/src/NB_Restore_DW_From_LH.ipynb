{"cells":[{"cell_type":"markdown","source":["##### Parameters\n","- workspaceName - The name of the workspace where the source warehouse exists\n","- warehouseName - The name of the warehouse that is to be backed up\n","- workspaceBackupName - The name of the workspace that the lakehouse for backups exists\n","- lakehouseBackupName - The name of the lakehouse used for back ups\n","- backupDateTime - The datetime that the backup took place. Get this value from the backup lakehouse folder."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aa8f81a1-aa1a-45b6-8749-56f987d66899"},{"cell_type":"code","source":["workspaceName = 'WS_Demo_InternetSales'\n","warehouseName = 'WH_InternetSales'\n","\n","workspaceBackupName = 'WS_Demo_InternetSales_Backup'\n","lakehouseBackupName = 'LH_DW_Backups'\n","backupDatetime = '20241210_1450'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8f0370d-59c9-469e-85b9-4f4ca9bebc79"},{"cell_type":"code","source":["# https://www.rakirahman.me/directory-recursion-synapse/\n","\n","def deep_ls(path: str, max_depth=1):\n","    \"\"\"\n","    List all files and folders in specified path and\n","    subfolders within maximum recursion depth.\n","    \"\"\"\n","\n","    # List all files in path\n","    li = mssparkutils.fs.ls(path)\n","\n","    # Return all files\n","    for x in li:\n","        if x.size != 0:\n","            yield x\n","\n","    # If the max_depth has not been reached, start\n","    # listing files and folders in subdirectories\n","    if max_depth > 1:\n","        for x in li:\n","            if x.size != 0:\n","                continue\n","            for y in deep_ls(x.path, max_depth - 1):\n","                yield y\n","\n","    # If max_depth has been reached,\n","    # return the folders\n","    else:\n","        for x in li:\n","            if x.size == 0:\n","                yield x\n","\n","fileList = deep_ls(f'abfss://{workspaceBackupName}@onelake.dfs.fabric.microsoft.com/{lakehouseBackupName}.Lakehouse/Files/{workspaceName}/{warehouseName}/{backupDatetime}', max_depth=2)\n","\n","tableList = []\n","for file in fileList:\n","    schema = file.path.split('/')[-2]\n","    table = file.name\n","    print(f'{schema = }, {table = }')\n","    tableList.append({\"schema\": schema, \"table\": table})"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8ba470f-b040-4823-ae64-c4110069baee"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","import requests, json\n","\n","header = {'Authorization': f'Bearer {mssparkutils.credentials.getToken(\"pbi\")}'\n","          ,\"Content-Type\": \"application/json\"\n","        }\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces', headers=header)\n","for workspace in response.json().get('value'):\n","  if workspace.get('displayName') == workspaceName:\n","    workspaceId = workspace.get('id')\n","  elif workspace.get('displayName') == workspaceBackupName:\n","    workspaceBackupId = workspace.get('id')\n","\n","print(f'{workspaceId = }\\n{workspaceBackupId = }')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5ddf0f66-0fe1-48f5-8c91-0a4b1ee04be2"},{"cell_type":"markdown","source":["##### Create temporary restore lakehouse in the workspace where the warehouse exists. \"LH_temp_restore_{warehouseName}_{backupDateTime}"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b6147b2-ce0f-44fe-86d2-cb971ffd71c1"},{"cell_type":"code","source":["lakehouseTempRestoreName = f\"LH_temp_restore_{warehouseName}_{backupDatetime}\"\n","\n","body = {\n","    \"displayName\": lakehouseTempRestoreName\n","}\n","\n","response = requests.request(method='post', url=f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/lakehouses', headers=header, data=json.dumps(body))\n","print(response.status_code)\n","print(response.json())\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9435abd2-c388-4bbc-9ca1-0b2b56c109c7"},{"cell_type":"markdown","source":["##### Get The lakehouse ids"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e8480615-7f66-4d53-9660-6c6d68be28fb"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","import requests, json\n","\n","header = {'Authorization': f'Bearer {mssparkutils.credentials.getToken(\"pbi\")}'\n","          ,\"Content-Type\": \"application/json\"\n","        }\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceBackupId}/lakehouses', headers=header)\n","for item in response.json().get('value'):\n","  if item.get('displayName') == lakehouseBackupName:\n","    lakehouseBackupId = item.get('id')\n","\n","response = requests.request(method='get', url=f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/lakehouses', headers=header)\n","for item in response.json().get('value'):\n","    lakehouseTempRestoreId = item.get('id')\n","\n","print(f'{lakehouseBackupId = }\\n{lakehouseTempRestoreId = }')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"43a63db3-a1a3-442d-84f8-8625fa932345"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","import requests, json\n","\n","\n","workspaceIdTarget = workspaceId\n","itemIdTarget = lakehouseTempRestoreId\n","\n","workspaceIdSource = workspaceBackupId\n","itemIdSource = lakehouseBackupId\n","\n","\n","url = f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceIdTarget}/items/{itemIdTarget}/shortcuts' #?shortcutConflictPolicy=GenerateUniqueName'\n","\n","for table in tableList:\n","    body = {\n","        \"name\": f\"{table.get('schema')}_{table.get('table')}\"\n","        ,\"path\": \"Tables\"\n","        ,\"target\": {\n","            \"oneLake\": {\n","                \"itemId\": itemIdSource\n","                ,\"path\": f\"Files/{workspaceName}/{warehouseName}/{backupDatetime}/{table.get('schema')}/{table.get('table')}\"\n","                ,\"workspaceId\": workspaceIdSource\n","            }\n","        }\n","    }\n","    \n","    response = requests.request(method='post', url=url, headers=header, data=json.dumps(body))\n","    print(response.status_code)\n","    print(f'{response.status_code} - {response.json()}')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb8bbd05-5657-4b5b-8141-ceb88e3ad366"},{"cell_type":"code","source":["import pyodbc, struct, itertools, time, datetime, re, uuid, json\n","\n","fabricDWServer = 'n52dzjnhphme5jslxpytuo62ni-bwqqnh23wdjude66jg7pd6kctu.datawarehouse.fabric.microsoft.com'\n","\n","connectionString = f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={fabricDWServer};Database={workspaceName}'\n","\n","# Use the credentials of the user executing the notebook\n","token = bytes(mssparkutils.credentials.getToken('pbi'), \"UTF-8\")\n","encoded_bytes = bytes(itertools.chain.from_iterable(zip(token, itertools.repeat(0))))\n","tokenstruct = struct.pack(\"<i\", len(encoded_bytes)) + encoded_bytes\n","\n","def get_result_set(cursor):\n","    if cursor.description:\n","        resultList = cursor.fetchall()\n","        resultColumns = columns = [column[0] for column in cursor.description]\n","    else:\n","        resultList = []\n","        resultColumns = []\n","    return [dict(zip(resultColumns, [str(col) for col in row])) for row in resultList]\n","\n","with pyodbc.connect(connectionString, attrs_before = { 1256:tokenstruct }) as conn:\n","    for table in tableList:\n","        with conn.cursor() as cursor:\n","            queryStatement = f'TRUNCATE TABLE {warehouseName}.{table.get(\"schema\")}.{table.get(\"table\")}; INSERT INTO {warehouseName}.{table.get(\"schema\")}.{table.get(\"table\")} SELECT * FROM {lakehouseTempRestoreName}.dbo.{table.get(\"schema\")}_{table.get(\"table\")}'\n","            print(queryStatement)\n","\n","            cursor.execute(queryStatement)\n","            \n","            queryMessage = str(cursor.messages) if cursor.messages else \"\"\n","            print(queryMessage)\n","            \n","            resultSet = get_result_set(cursor)\n","            print(resultSet)\n","\n","            cursor.commit()\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7a792a49-eb5e-4f00-95b8-70d1ae25c8ce"},{"cell_type":"markdown","source":["##### Drop the temporary lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"63d960af-e016-4c90-8210-9d5471a027d5"},{"cell_type":"code","source":["header = {'Authorization': f'Bearer {mssparkutils.credentials.getToken(\"pbi\")}'\n","          ,\"Content-Type\": \"application/json\"\n","        }\n","        \n","response = requests.request(method='delete', url=f'https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/lakehouses/{lakehouseTempRestoreId}', headers=header)\n","\n","print(response.status_code)\n","print(response.text)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ca8309ef-656c-4b51-b505-45d2c9da43e9"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a43b6242-876f-479f-8caa-4716ebafc4be"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}